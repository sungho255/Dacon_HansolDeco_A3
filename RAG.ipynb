{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVseHXnSuwJx"
   },
   "source": [
    " # 개발 환경 OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1743064329783,
     "user": {
      "displayName": "김성호",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "t_-1LOlfuauY",
    "outputId": "d28f8171-6609-49f2-f79a-b24468008d99"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1743064311707,
     "user": {
      "displayName": "김성호",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "j5tqN3NiugIn",
    "outputId": "2f261b0d-0da2-457d-9791-5d2f9e736752"
   },
   "outputs": [],
   "source": [
    "# !head /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1743064312234,
     "user": {
      "displayName": "김성호",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "VuIfcnhFugVJ",
    "outputId": "3201cec3-9fed-4406-8901-d7dde0ee64da"
   },
   "outputs": [],
   "source": [
    "# !head -n 3 /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1743064962130,
     "user": {
      "displayName": "김성호",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "c2kmpVbKxGeN",
    "outputId": "65060af2-1d37-4676-e9cd-ee2e8e3eee04"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwsYg3SjA1Ui"
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2218,
     "status": "ok",
     "timestamp": 1743068114842,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "TsGvmOjRNhVn",
    "outputId": "bbd7655d-ac3b-4f55-f860-360ffbdc064d"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8nyvO82AOVR"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain-community langchain-text-splitters langchain langchain-huggingface rank_bm25 transformers torch faiss-cpu pymupdf datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHDfOGR6BaA9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import langchain\n",
    "import langchain_community\n",
    "import langchain_huggingface\n",
    "import transformers\n",
    "import pkg_resources\n",
    "import sentence_transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import  BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1743062445506,
     "user": {
      "displayName": "김성호",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "J0QPt_7UkwZo",
    "outputId": "0d88b0a0-50f8-4971-8a2e-6e70ffade643"
   },
   "outputs": [],
   "source": [
    "# print(f\"torch version: {torch.__version__}\")\n",
    "# print(f\"pandas version: {pd.__version__}\")\n",
    "# print(f\"tqdm version: {pkg_resources.get_distribution('tqdm').version}\")\n",
    "# print(f\"transformers version: {transformers.__version__}\")\n",
    "# print(f\"sentence_transformers version: {sentence_transformers.__version__}\")\n",
    "# print(f\"langchain version: {langchain.__version__}\")\n",
    "# print(f\"langchain_community version: {langchain_community.__version__}\")\n",
    "# print(f\"langchain_huggingface version: {pkg_resources.get_distribution('langchain_huggingface').version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G14tlIYwAoL6"
   },
   "source": [
    "# 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25662,
     "status": "ok",
     "timestamp": 1743068155009,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "Yn2tkyLBA91H",
    "outputId": "b6273005-414a-4f18-d4b5-c0acfa0ebe74"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9y2aROLlAoSh"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/MyDrive/# 협동 업무/한솔데코 데이콘/A3/' # Colab에서 실행 시\n",
    "path = '/' # Local 환경에서 실행 시\n",
    "db_path = path + 'DB/'\n",
    "vectorstore_path = path + 'VectorStore/'\n",
    "model_path = path + 'Model/'\n",
    "score_path = path + 'TestScore/'\n",
    "submission_path = path + 'Submission/'\n",
    "\n",
    "# PDF File 경로\n",
    "pdf_path = path + '건설안전지침/'\n",
    "file_list = os.listdir(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlRYnJSDAoYU"
   },
   "source": [
    "# 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjDue8IwAohB"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(db_path + 'test_preprocessing.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "test['공사종류(대분류)'] = test['공사종류'].str.split(' / ').str[0]\n",
    "test['공사종류(중분류)'] = test['공사종류'].str.split(' / ').str[1]\n",
    "test['공종(대분류)'] = test['공종'].str.split(' > ').str[0]\n",
    "test['공종(중분류)'] = test['공종'].str.split(' > ').str[1]\n",
    "test['사고객체(대분류)'] = test['사고객체'].str.split(' > ').str[0]\n",
    "test['사고객체(중분류)'] = test['사고객체'].str.split(' > ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YTwLOLwAojq"
   },
   "outputs": [],
   "source": [
    "# test data 전처리\n",
    "data_test = test.apply(\n",
    "    lambda row: {\n",
    "        \"process\": row[\"작업프로세스\"],\n",
    "        \"construct_type\": row[\"공종(중분류)\"],\n",
    "        \"object_type\": row[\"사고객체(중분류)\"],\n",
    "        \"reason\": row['사고원인'], # 사고원인 추가\n",
    "        \"situation\": (\n",
    "            f\"'{row['공사종류(대분류)']}' 공사 중 '{row['공종(중분류)']}' 작업 중 '{row['사고원인']}'으로 인해 사고가 발생하였습니다.\"),\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# DataFrame으로 변환\n",
    "data_test = pd.DataFrame(list(data_test))\n",
    "\n",
    "# Test 입력 데이터 설정\n",
    "query = data_test[\"situation\"].tolist() # 질문 데이터 리스트로 변환\n",
    "\n",
    "# # pdf 뽑아낼 construct_type_query 설정\n",
    "construct_type_query = data_test[\"construct_type\"].tolist()  # \"공종(중분류)\"을 construct_type_query로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1743068198731,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "6bkj5L4_L09U",
    "outputId": "5c5da76a-c787-4b09-c5eb-5e56bdfd87de"
   },
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cW6i8zdlAonu"
   },
   "source": [
    "# 함수 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiYy6GYgG0If"
   },
   "source": [
    "## 1) Chunking 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbobDLgEAotI"
   },
   "outputs": [],
   "source": [
    "# 1. Content Chunking 함수 => 의미 기반\n",
    "def chunking():\n",
    "    documents = []\n",
    "    paths = []\n",
    "    total_columns = 0\n",
    "\n",
    "    # 텍스트 분할기\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=overlap)\n",
    "\n",
    "    # Chunking\n",
    "    for idx, file in enumerate(file_list):\n",
    "        # 1. 텍스트 파일을 load -> List[Document] 형태로 변환\n",
    "        loader = PyMuPDFLoader(pdf_path + file)\n",
    "\n",
    "        # 2. 문서 분할\n",
    "        chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "        # 3. 각 청크를 벡터화하고 삽입\n",
    "        for chunk in chunks:\n",
    "            documents.append(chunk.page_content)\n",
    "            paths.append(file)\n",
    "\n",
    "        print(\"=\"*50)\n",
    "        print(f\"{idx+1} 파일 명: {file}, 분할 개수: {len(chunks)}\")\n",
    "\n",
    "        # 4. 전체 컬럼 수\n",
    "        # 전체 컬럼 수 세기\n",
    "        total_columns += len(chunks)\n",
    "        # 전체 컬럼 수 출력\n",
    "        if idx == len(file_list)-1:\n",
    "            print(f\"DB 총 Column 수 : {total_columns}\")\n",
    "\n",
    "    return documents, paths\n",
    "\n",
    "# 2.sparse 기반 chunking => 키워드 기반\n",
    "def sparse_chunking(file: str):\n",
    "    documents = []\n",
    "    total_columns = 0\n",
    "\n",
    "    # 텍스트 분할기\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=overlap)\n",
    "\n",
    "    # Chunking\n",
    "    # 1. 텍스트 파일을 load -> List[Document] 형태로 변환\n",
    "    loader = PyMuPDFLoader(pdf_path + file)\n",
    "\n",
    "    # 2. 문서 분할\n",
    "    chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "    # 3. 각 청크를 벡터화하고 삽입\n",
    "    for chunk in chunks:\n",
    "        documents.append(chunk.page_content)\n",
    "\n",
    "    # 4. 전체 컬럼 수\n",
    "    # 전체 컬럼 수 세기\n",
    "    total_columns += len(chunks)\n",
    "\n",
    "    print(f\"DB 총 Column 수 : {total_columns}\")\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts_PBTF_G4jP"
   },
   "source": [
    "## 2) VectorStore 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg4sHmuNHXRZ"
   },
   "outputs": [],
   "source": [
    "# 3. Title_DenseVectorDB 생성 및 저장\n",
    "def title_vector_store_save(folder_name: str, file_list: list):\n",
    "    # PDF 제목 리스트\n",
    "    pdf_titles = [file.replace('.pdf', '') for file in file_list]\n",
    "\n",
    "    # 임베딩 모델\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    print(\"DB 생성 중...\")\n",
    "    db = FAISS.from_texts(pdf_titles,\n",
    "                        embedding=embedding_model,\n",
    "                        # docstore=InMemoryDocstore(),\n",
    "                        metadatas=[{\"path\": p} for p in file_list])\n",
    "    print(\"DB 생성 완료\")\n",
    "\n",
    "    print(\"DB 저장 중...\")\n",
    "    db.save_local(folder_name)\n",
    "    print(\"DB 저장 완료\")\n",
    "\n",
    "# 4. Content_DenseVectorDB 생성 및 저장\n",
    "def content_vector_store_save(folder_name: str):\n",
    "    # 임베딩 모델\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "    documents, paths = chunking()\n",
    "    print(\"DB 생성 중...\")\n",
    "    db = FAISS.from_texts(documents,\n",
    "                        embedding=embedding_model,\n",
    "                        # docstore=InMemoryDocstore(),\n",
    "                        metadatas=[{\"path\": p} for p in paths])\n",
    "    print(\"DB 생성 완료\")\n",
    "\n",
    "    print(\"DB 저장 중...\")\n",
    "    db.save_local(folder_name)\n",
    "    print(\"DB 저장 완료\")\n",
    "\n",
    "# #VectorDB에 PDF Chunk화 하여 저장\n",
    "# title_vector_store_save('Title_DB',file_list)\n",
    "# content_vector_store_save('Content_DB')\n",
    "\n",
    "# 5. 저장된 벡터 스토어 로드\n",
    "def vector_store_load(folder_name: str):\n",
    "    \"\"\"\n",
    "    FAISS 벡터 DB 로드 함수\n",
    "    \"\"\"\n",
    "    faiss_path = vectorstore_path + f\"{folder_name}\"  # 절대경로 사용\n",
    "\n",
    "    # FAISS 인덱스 파일이 존재하는지 확인\n",
    "    if not os.path.exists(f\"{faiss_path}/index.faiss\"):\n",
    "        raise RuntimeError(f\"FAISS 인덱스 파일을 찾을 수 없습니다: {faiss_path}/index.faiss\")\n",
    "\n",
    "    # FAISS 벡터 DB 로드\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-sts\")\n",
    "    vector_store = FAISS.load_local(faiss_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "    print(f\"FAISS 벡터 DB 로드 성공: {faiss_path}\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zt7rzg1jHZrz"
   },
   "source": [
    "## 3) Combine Chunked Text 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCMWr9W2H-1T"
   },
   "outputs": [],
   "source": [
    "# 4. 검색한 청크들을 하나의 청크로 합치는 함수.\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    검색한 청크들을 하나의 청크로 합치는 함수.\n",
    "\n",
    "    Args:\n",
    "        docs (list): Faiss로 부터 검색한 내용을 담은 리스트\n",
    "\n",
    "    Returns:\n",
    "        list: 하나의 청크로 합친 리스트\n",
    "    \"\"\"\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"{doc.page_content}\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ198kEJNLUc"
   },
   "source": [
    "# Model 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11246,
     "status": "ok",
     "timestamp": 1743068214492,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "EaZVQWMoNNjf",
    "outputId": "7191531d-dc50-483e-f238-14ae4498aecf"
   },
   "outputs": [],
   "source": [
    "model_name = 'kobart7'\n",
    "\n",
    "# 저장된 모델 경로\n",
    "load_model_path = model_path + model_name\n",
    "\n",
    "# 모델 & 토크나이저 로드\n",
    "model = BartForConditionalGeneration.from_pretrained(load_model_path, device_map=\"auto\", num_labels=2)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(load_model_path)\n",
    "print(\"모델과 토크나이저가 정상적으로 로드되었습니다!\")\n",
    "\n",
    "print(\"pad_token:\", tokenizer.pad_token)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DflIEzeRAoxd"
   },
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SshMnG_oGIBI"
   },
   "source": [
    "## VectorStore 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438,
     "referenced_widgets": [
      "67ba2da202284edfb56f32eaf59e68b1",
      "df5bbe7220e74ee796bfe38c7e3bbd73",
      "ce9ce5ddcfdd4314babd8fb61902eb04",
      "7168cf71aee8435fac06f23563fe01eb",
      "5e9c876d194d4bb79fd6ae15777648ee",
      "03103610d4fc4c01aba0755895f2cf15",
      "bb1a88654ce3438f9d8bfa75ae298e6c",
      "7998e8e7294c491389199e4e49541858",
      "57684e9af1b44526bbceb7c52fb02bed",
      "b241dba6505c41f09c81078f52d10744",
      "32fcfb1f2a1549c7a458ce48d170f74b",
      "78654a8596284788a3547593c37bd6ee",
      "be598f3d84b44ccaaac35608e3486553",
      "86a6dca4632843f2aaf41488c185de28",
      "c83b439da6f042a4b8e8a3c2d2f67a56",
      "b75eb5390e2547cd8422f005112ea46d",
      "974c0a0f3ca3452c9a0d7f1b8130a377",
      "3daa4857d65e4186894a6a5651a65e46",
      "0fcd2257b8094432820881679d855759",
      "4e9c402e85264c2c9aa10064a244ede2",
      "fa6dda283a8f4fa9a1fd60ff44e51110",
      "306f9b9d6d644641a72c587876f6542f",
      "60519d7053844f8c964e97d28d343fe4",
      "fc85c413dfab449984580763b3e2898d",
      "8a0ad1fafb6b41a685cec25b2526fd7d",
      "af096fe6578841ad9fa699202874e7df",
      "552d139d5e8449bb98a983a1554dfb82",
      "16c9f60c63c343bcbc1ba925d1571f80",
      "12ec03d8de3e4039923b607e40bc064c",
      "9af54bc56b674f279c7fc3182c977026",
      "2943abf05a5242a4a49b751b079db856",
      "acf3cbcf6c3445baa82eed65af31daad",
      "12918f20043f4951858de77b8a8acc0a",
      "f50adc3f19464c7cbcb4978bba3fab6f",
      "7e60af2c894947b6b63cfe678966b664",
      "e921dddc17e649b383d45266afff6b4a",
      "346c952b85f84628b98dc3ff17b9c924",
      "e2cdb95561534c4e80a33ecf1b65628f",
      "298a7f1cf4d940b7b87069757644066b",
      "39791206e60e420888dd82f2ce5c6251",
      "bd7dccdf621a4e7ca469c38bc7a5b54b",
      "36dea6726a294a61b25d1f022ac3240f",
      "6b101521218541c681b5c3d1385430e2",
      "41eda6c6e378429cbb242486cc4f5d0e",
      "425a83ec57b24875a0c3d6931ce4ab97",
      "3fcf7d8c711743738a62c2f0a0162433",
      "6a19e938bda347a98f4547014401ed50",
      "33aacdb3b86a42fbb84f22e8e80688fc",
      "3c711ffdea9444e19a965f61b81213d0",
      "2790ba42e97344c89e10b233ba549a19",
      "73c6909efeab4856825a5a0fa6de5997",
      "ed2aa2130d5e4c9db4da685357b13520",
      "64d3e7f1c9954a3bba5340f7e3d8425c",
      "7782002c95b646e6b502b583b0630e6b",
      "36f00d45a79e412f8d02673a50a4f9fb",
      "4797d2e2f39c492cb2fafd5b149ece6a",
      "eaaa84bb82364a1b8f683394b59022dc",
      "1a653e478eb84e0ab6be31bb62cc5e5a",
      "1b6187cfbe2c42f49a0bbd2bf4d8e910",
      "b3ab4ac1f4a5485cb189df9be4681092",
      "dd7a68b65d7144b4ba4641884a67f19c",
      "4f6e02d8e2194ea2ab9112fe30275a97",
      "ee9376252d6c4513bb8eb7e9576b4c3a",
      "abfd98df209444a1bcf7756f6ecda45f",
      "6de7b68c4efe412591edb68f58d00c82",
      "6f5809b0a6ad4f2eadac861b8c05d12f",
      "52b6c71cdaf64547b1d1f54d10caf910",
      "d09522e2e785410daaeb6130c814ae2f",
      "a57a667872b24f8586422749da6c1954",
      "26c42bd219f94b51a98994bdbbf3f56d",
      "876869a660b64fecacbfa0c787b2d56c",
      "bb4c273f72c04e0ab5bc5d0f914ebe42",
      "998f363d5d234ed6a95d837bbd294fbe",
      "72102bb78e4b42628b792a26f8a565f2",
      "8ebd4f78539a47fc8764fb6e23a4967b",
      "4ed11068d6b84434ba9644fee5d2a0d9",
      "876aa84c4acd415ba9dac2fbed458ffa",
      "89eeb2048a4b4696a0a74ef5b60a6cbb",
      "8ec97f29801b4f1c89e9935390d21242",
      "ad5c62d3b65b4f5db6a85d335680cdcb",
      "6e849a932fcc472997e2b4742a6425e1",
      "b63701d1ade94b50837adebb207e96e4",
      "cfa21e9c00cf43c193425162498d353a",
      "b7273e4ae7fa40f0a800930d8f43c3e9",
      "b140c58aaaf2456c8023b6221cbebfa1",
      "b958c72773fd4e12a49590a4b0162434",
      "ae806d9234994d35bb8af8f9f0f7fe0a",
      "7c47cbeb1f0c47ec9d3a4104a29a0e3e",
      "7271a563403f4c46a09c66e644cd4028",
      "994b4b52469a45118766621bd64ac240",
      "005a33422cbc46f085f3a45009364798",
      "b4bc295ff0b74d7cbdddd24e0549b2c0",
      "64f8940042ee4a8183f2f8a648608ba9",
      "71a369fc34bc4420a38ea8bbba686319",
      "11fb91d0c21d439688bac255b3623003",
      "1de880aebb1847ae9951e9cc6abc23cf",
      "b578c83d520441f7a9c5ad528a3d2536",
      "ac5ee2f65398438ab38d7f7a4c3c7e57",
      "dfdcb90dbd3846428ddbd9e3bb911408",
      "dae63b0a8cf646b0a13a437e406d7fdd",
      "116725bacd2348398f3ce1a847f6658b",
      "658a7cf912d34f6c9dd039bf748cf5c4",
      "348039dc7ed04b7fb10c4d7551061d30",
      "4f6e3c7e5a6e4467a3ea06c547ee0de1",
      "b646d398fd954567bced71c415c0b539",
      "a519958f593742ddadb294958e33a635",
      "877fec3044bb41519e6f1160ad78e3dc",
      "0b56b37fc23041f3954b19a79b4d3b49",
      "52716934c1c84d9d86707d705b841458",
      "af0b294b5eda4aa39eb5e7e8a1125048",
      "05cc05596d2f4e2583fa185a79b945c3",
      "56ea2d8ab8d04f1d9f0041b0a3da3b88",
      "ed7c0c27e61848838f15ddc2f27e2218",
      "bee0d8adb58c4a59b9196b9bf793c2f9",
      "5e8352668314474baaf494a8883e7086",
      "ced9f11df2ea493db5943b5c365e00b8",
      "2960acaf8f1c4ec59307d64dfc5b7886",
      "0acc8986339d4af3972a99dc0b4a8f21",
      "109554960a0940538c2fde997ae5f51c",
      "a0877cdcd7b347a090a1dbcf960d3a42",
      "ec5038cc53e748a29f1cb30d572ade74",
      "dabed8b74b1e4352b1e5cad9319dff3d",
      "50d78bf5ed2d4786a62214ad3e220146",
      "fc4c9be253d7460a9cc089ae6579739d",
      "bbb5a341d2bb48c6be9e309c651c1643",
      "631b9c2152564019a1f5d8e9d5bebd35",
      "4e002d984528403087ad9c40023acde9",
      "6adae867f9624fb5a7b5ac31eb506b1f",
      "3e588296dd154a068d9e899a98d07d58",
      "b5fae32f7de74c79a5a7216503ab0a8f",
      "578d5dd57c8e4294abc38c95cf2d9884",
      "b16c1accf5594d9bbd77f25a1045a3d4"
     ]
    },
    "executionInfo": {
     "elapsed": 28918,
     "status": "ok",
     "timestamp": 1743068243410,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "VJ8GwEULGNFQ",
    "outputId": "1ad27eac-00b5-4be8-ed8c-822d36457e2d"
   },
   "outputs": [],
   "source": [
    "# chunk size 조정\n",
    "size = 300\n",
    "overlap = 50\n",
    "\n",
    "# Hybrid Retriever 함수로 구성 (3개의 pdf)\n",
    "title_db = vector_store_load(\"Title_DB\")\n",
    "content_db = vector_store_load(f\"Content_DB_{size}_{overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUew-IM_Ao2x"
   },
   "outputs": [],
   "source": [
    "# re-rank retriever 함수로 구성 (3개의 pdf)\n",
    "def rerank_retriever(construct_type_query: str, query: str, k: int = 2):\n",
    "    \"\"\"\n",
    "    Fine-Tuned LLaMA + Hybrid Retriever 기반 RAG 실행 함수\n",
    "    construct_type_query: PDF 검색에 사용할 '공종(중분류)' 정보\n",
    "    query: 실제 검색에 사용할 '사고상황'\n",
    "    k: 검색할 PDF 개수\n",
    "    \"\"\"\n",
    "    print(f\"🔍 Hybrid Retriever 시작 → construct_type_query: {construct_type_query}, query: {query}\")\n",
    "\n",
    "    # 1. 저장된 FAISS 벡터 DB 로드\n",
    "    # embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    title_db = vector_store_load(\"Title_DB\")\n",
    "\n",
    "    # 2. FAISS 벡터 겁색 수행 -> '공종(중분류)'으로 가장 유사한 PDF 찾기\n",
    "    result = title_db.similarity_search(construct_type_query, k=3)  # 가장 유사한 3개 찾기\n",
    "\n",
    "    # 검색된 PDF 파일 목록\n",
    "    pdfs = [doc.metadata[\"path\"] for doc in result]\n",
    "    print(f\" 선택된 PDF: {pdfs}\")\n",
    "\n",
    "    # 3. Content DB 로드 (선택된 PDF에서 검색)\n",
    "    content_db = vector_store_load(f\"Content_DB_{size}_{overlap}\")\n",
    "\n",
    "    # FAISS 리트리버 생성 (Dense Retriever)\n",
    "    dense_retriever = content_db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"filter\": {\"path\": {\"$in\": pdfs}}, \"k\": k}  # 선택된 PDF에서 검색\n",
    "    )\n",
    "\n",
    "    # 4. BM25를 위한 Sparse 검색 수행\n",
    "    all_documents = []\n",
    "    for pdf in pdfs:\n",
    "        # BM25 검색용 문서 객체 생성\n",
    "        documents = [Document(page_content=doc) for doc in sparse_chunking(pdf)]\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "    sparse_retriever = BM25Retriever.from_documents(all_documents)\n",
    "\n",
    "    # 5. Hybrid Retriever 생성 (FAISS + BM25 결합)\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[sparse_retriever, dense_retriever],\n",
    "        weights=[0.7, 0.3]  # 가중치 설정\n",
    "    )\n",
    "\n",
    "    # Re-Rank 모델 설정\n",
    "    reranker_model_name = \"BAAI/bge-reranker-v2-m3\"  # Hugging Face Re-Ranker 모델\n",
    "\n",
    "    rerank_model = HuggingFaceCrossEncoder(model_name=reranker_model_name)\n",
    "    compressor = CrossEncoderReranker(model=rerank_model, top_n=k) # 가져오고자 하는 청크의 갯수를 top_n에 기입\n",
    "\n",
    "    # re-ranker 적용\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=ensemble_retriever\n",
    "    )\n",
    "\n",
    "    return compression_retriever\n",
    "\n",
    "def hybrid_retriever(construct_type_query: str, query: str, k: int = 2):\n",
    "    \"\"\"\n",
    "    Fine-Tuned LLaMA + Hybrid Retriever 기반 RAG 실행 함수\n",
    "    construct_type_query: PDF 검색에 사용할 '공종(중분류)' 정보\n",
    "    query: 실제 검색에 사용할 '사고상황'\n",
    "    k: 검색할 PDF 개수\n",
    "    \"\"\"\n",
    "    # 1. FAISS 벡터 겁색 수행 -> '공종(중분류)'으로 가장 유사한 PDF 찾기\n",
    "    result = title_db.similarity_search(construct_type_query, k=3)  # 가장 유사한 3개 찾기\n",
    "\n",
    "    # 검색된 PDF 파일 목록\n",
    "    pdfs = [doc.metadata[\"path\"] for doc in result]\n",
    "\n",
    "    # 2. Content DB 로드 (선택된 PDF에서 검색)\n",
    "\n",
    "    # FAISS 리트리버 생성 (Dense Retriever)\n",
    "    dense_retriever = content_db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"filter\": {\"path\": {\"$in\": pdfs}}, \"k\": k}  # 선택된 PDF에서 검색\n",
    "    )\n",
    "\n",
    "    # 3. BM25를 위한 Sparse 검색 수행\n",
    "    all_documents = []\n",
    "    for pdf in pdfs:\n",
    "        # BM25 검색용 문서 객체 생성\n",
    "        documents = [Document(page_content=doc) for doc in sparse_chunking(pdf)]\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "    sparse_retriever = BM25Retriever.from_documents(all_documents)\n",
    "\n",
    "    # 4. Hybrid Retriever 생성 (FAISS + BM25 결합)\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[sparse_retriever, dense_retriever],\n",
    "        weights=[0.2, 0.8]  # 가중치 설정\n",
    "    )\n",
    "\n",
    "    return ensemble_retriever\n",
    "\n",
    "# ensemble retriever에서 query관련 청크들 뽑아오기\n",
    "def retrieved_chunk(construct_type_query: str, query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Hybrid Retriever를 사용하여 query에 대한 관련 청크 검색\n",
    "    \"\"\"\n",
    "    ensemble_retriever = hybrid_retriever(construct_type_query, query, k)\n",
    "\n",
    "    # 검색된 관련 청크 리스트 반환\n",
    "    retrieved_chunks = ensemble_retriever.invoke(query)\n",
    "\n",
    "    # 검색된 청크를 하나의 텍스트로 변환\n",
    "    retrieved_text = format_docs(retrieved_chunks)\n",
    "\n",
    "    return retrieved_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cAsZ2Y8KItg"
   },
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoEojb7hAo-M"
   },
   "outputs": [],
   "source": [
    "# LangChain Prompt Template 생성(파인튜닝한 템플릿 유지 + 검색된 청크 활용)\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"process\",\"construct_type\", \"object_type\", \"context\", \"situation\"],\n",
    "    template=(\n",
    "'''\n",
    "제공된 data는 건설 공사현장에서 발생한 사고 상황입니다. 주어진 situation을 분석하고 context를 참고해 재발방지 대책을 포함한 대응책을 response에 작성하세요.\n",
    "### context:\n",
    "{context}\n",
    "\n",
    "### process:\n",
    "{process}\n",
    "\n",
    "### construct_type:\n",
    "{construct_type}\n",
    "\n",
    "### object_type:\n",
    "{object_type}\n",
    "\n",
    "### situation:\n",
    "{situation}\n",
    "\n",
    "※ Example response:\n",
    "- 작업자 안전교육 및 재발 방지 대책 수립과 작업 전 안전교육 철저 및 관리자 추가 배치를 통한 동종 사고 예방.\n",
    "- 근로자 보행 통로 구간 안전표지판 설치와 특별안전교육 실시, 일일 작업 투입 전 상시 교육, 관리 대상 선정 등을 통한 이동 구간 보행 안전 확보와 작업자 안전 교육 지시.\n",
    "\n",
    "### response:\n",
    "''')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd60O18TApD2"
   },
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRT9uBf6KTka"
   },
   "outputs": [],
   "source": [
    "# generate_text 함수\n",
    "def generate_answer(ts, prompt, model, tokenizer, max_new_tokens=65):\n",
    "    \"\"\"\n",
    "    주어진 프롬프트를 기반으로 모델이 재발 방지 대책 및 향후 조치 계획을 생성하는 함수\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    )\n",
    "\n",
    "\n",
    "    process = ts['process']\n",
    "    construct_type = ts['construct_type']\n",
    "    object_type = ts['object_type']\n",
    "    situation = ts['situation']\n",
    "    reason = ts['reason']\n",
    "\n",
    "\n",
    "    # 입력 문장 토큰화 및 GPU로 이동\n",
    "    input_ids = tokens.input_ids.to(device)\n",
    "    # print('prompt:',tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "    attention_mask = tokens.attention_mask.to(device)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.7,\n",
    "        top_k=40,\n",
    "        top_p=0.85,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id  # <-- 이 부분이 핵심\n",
    "    )\n",
    "\n",
    "\n",
    "    # 생성된 토큰을 다시 문장으로 변환\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # ✅ 후처리: 마지막 마침표(.)까지만 자르기\n",
    "    if '.' in generated_text:\n",
    "        last_period_index = generated_text.rfind('.')  # 마지막 마침표 위치\n",
    "        generated_text = generated_text[:last_period_index + 1].strip()\n",
    "    else:\n",
    "        generated_text = generated_text.strip()\n",
    "\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# RAG 실행 (Hybrid Retriever + kobart)\n",
    "def rag_pipeline(ts, model, tokenizer, k=2):\n",
    "    \"\"\"\n",
    "    RAG 시스템 실행: Hybrid Retriever → Fine-tuned kobart 기반 생성\n",
    "    \"\"\"\n",
    "    # print(\"🔍 RAG 실행 시작...\")\n",
    "\n",
    "    # Hybrid Retriever 실행하여 관련 문서 청크 검색\n",
    "    retrieved_text = retrieved_chunk(ts['construct_type'], ts['situation'], k) # 'situation'(사고상황)에서 'reason'(사고원인)으로 변경\n",
    "\n",
    "\n",
    "    # 프롬프트 포맷팅\n",
    "    formatted_prompt = prompt_template.format(process=ts['process'],\n",
    "                                              construct_type=ts['construct_type'],\n",
    "                                              object_type=ts['object_type'],\n",
    "                                              context=retrieved_text,\n",
    "                                              situation=ts['situation'])\n",
    "\n",
    "    # 문장 생성 함수 호출\n",
    "    generated_response = generate_answer(ts, formatted_prompt, model, tokenizer)\n",
    "\n",
    "    return generated_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ9GjqFvQOJf"
   },
   "source": [
    "## 추론 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12760,
     "status": "ok",
     "timestamp": 1743068256266,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "vF6sFsBNKTwZ",
    "outputId": "20b637e2-c26d-4464-cf8a-98bf972028e9"
   },
   "outputs": [],
   "source": [
    "# 랜덤하게 10개의 인덱스 선택\n",
    "random_indices = random.sample(range(len(data_test)), 10)\n",
    "\n",
    "for i in random_indices:\n",
    "    ts = data_test.iloc[i]\n",
    "    process = ts['process']\n",
    "    construct_type = ts['construct_type']\n",
    "    object_type = ts['object_type']\n",
    "    situation = ts['situation']\n",
    "    generated_text = rag_pipeline(ts, model, tokenizer)\n",
    "    print(f\"사고 상황: {situation}\")\n",
    "    print(f\"생성된 문장: {generated_text}\")\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA1wM2kbKTqT"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 738417,
     "status": "ok",
     "timestamp": 1743068994699,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "xaRr0j7MKT1L",
    "outputId": "0bdec32f-1e9f-4a5d-99af-c6ad4c796d99"
   },
   "outputs": [],
   "source": [
    "# 테스트 실행 및 결과 저장\n",
    "test_results = []\n",
    "\n",
    "print(\"테스트 실행 시작... 총 테스트 샘플 수:\", len(data_test))\n",
    "\n",
    "for idx, row in tqdm(data_test.iterrows(), total=len(data_test), desc=\"Processing\"):\n",
    "    # RAG 체인 호출 및 결과 생성\n",
    "    generated_text = rag_pipeline(row, model, tokenizer)  # 개별 행(row) 전달\n",
    "    test_results.append(generated_text)\n",
    "\n",
    "print(\"\\n테스트 실행 완료! 총 결과 수:\", len(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419,
     "referenced_widgets": [
      "9e4f2dd21bd449b9a36093b7ac2a9035",
      "955d93ec0a644d9ab50515e2af3f96cd",
      "0e8f782743ee446e8982f11c6d798bcf",
      "580e7e6616f944ca9cca0d89cee2ebba",
      "14c2f5512f3542489be10a52367d53b2",
      "da9903a2594741cbbc9a712db55963a2",
      "90d5b2b773f04482ad32eb6f82630d4b",
      "08145901414a4572bc8faecd9829f8ae",
      "47dac9a1149f4ea2846af02f093a4531",
      "991149a173224d6f8bc474457c9ce699",
      "3ca477a1669c4140b04bd435c4b498fa",
      "2264ffd9125949ed8184439eece1380e",
      "cdcaa0e3d6b44a1d99661f07d0fd00f2",
      "3828d548c5074b968379b3be41d2f572",
      "d2b7f4a51d6c4fcfb12f92f80dee802a",
      "4a7371664a754805811d1a29559babef",
      "f9c9f41c880649dab7f6d82b6ad97bae",
      "36d4768f8ea947c4a6b933e9ec5b2088",
      "c644056c83f64afb8e327a199dd926bb",
      "b2249646dcd94d1a8a873d8115dd6a26",
      "b3d9e8f3970f4d858f7033688f8e4316",
      "550d6e06aee14c2fb637fb541ef6273d",
      "f3c46a143c63425f8dc14c2f39984c80",
      "84f1f4afbe474a28a11c7f07c2cb232d",
      "14ef9f85a5e844c9aa886919f7523c1a",
      "c9683511c9354d5a9c27a2b0183cbdaa",
      "5ab74c963d904b53af6ce3b95f278c33",
      "d7d9de1817354fcb8fbdb869be2e51a6",
      "73c95c48997c46059e08395cbf90b4ed",
      "24559150b3644ee3816891803cbe516b",
      "017d8a12d89b45fda73d611bcefd0667",
      "a46a484eb36b4616ae49e4037e1ab59b",
      "c1b052c141c34cae852ea74bf3f9a1b6",
      "4ddbd7e71a9a4b47af0335f8e987e226",
      "24d4d538f81b49e0ba5b5b1fd90e6a8c",
      "6a8425538972480cae9309312a0606c3",
      "b0391cd18ee047e79a011ebb805b1bcf",
      "6d2a8d73fca04d13a3a0eb72c5d7966c",
      "bd5918cf208c4fedb306976a2cb76919",
      "70c6b75814774f9c9335d4abf6f0eec0",
      "98afebbc254e4e3b8dd74fa886152582",
      "800970621adf4d889e7dea5d2cfc43b7",
      "121608618e1647e8bede99377f273f79",
      "d786b9846de74104b025b9ac46320834",
      "3d54e701905846fb890e51f94f89aa12",
      "56f048fb92564f92add5d9294a008a77",
      "3a7dbc6d43734391a302bacb36331e0b",
      "aa4bf612a6434201af2db582f0ff2036",
      "d15c4ad94556414cb392334795ef5a75",
      "6ac146bff1be4ed4b89c9169344a5bb3",
      "d8d8bc76a7954fe2b14a28d746987ff8",
      "6eea708e0ba8471998591a1af77299fa",
      "de7a58266deb4aaa86454526f63fc9b5",
      "a80ae20debb4471991f984a83b48d0a3",
      "71b47f5959114f4192a095b9b11b8a97",
      "5fa3a683cf5f4d74895974635beb4a08",
      "a9338321ca1b46b49dd05a449b9be297",
      "a39cfddbfc984466a88cdd9f8e9cbcfe",
      "0e8919e9887f45ae8ca2e7ae34620f9a",
      "9af55322bb30480caf15218c51e1af72",
      "9f3763dbdd854ef08372819198faf605",
      "d92d656cb81e480cb7c29658e2bb4303",
      "41d6801594c040e99a778a64d6be3599",
      "d67813fe137b4872a505f26433645705",
      "b26d505395c54a779c2e3880f125ecb5",
      "321e717556a54aeb841eeaf904ba0394",
      "760a168618b6403c8a52a8403a813fb8",
      "54597ec970ff434c89546a10feb7dca2",
      "7e857c4ea4d34e21acb3f1e86be0234b",
      "644c3313f64f4600b6d25a95b6096252",
      "94b4cd7fe1724c53ac146b277add0263",
      "b7cde26aea7e407da14074be5120c36d",
      "df94987aba3548afaf832e46bc7f03cc",
      "650e3c68562b4045ba98d847bf8e92d6",
      "83236de0042b4816806dfe505e86ef8d",
      "fca622cf453e4a269196bcfc96cce7a6",
      "c45cb9b142d74bf78313de67d6210116",
      "56dc585569d94c089d47521fa80a39d3",
      "2498ffee40074b3a8e4fada352725425",
      "28fd0f521edc437fac11a3199b240586",
      "8df8dbb9cb244b48b577ed6c78620d5b",
      "f6d2d392dbfb465691a7d64c3e2a05d3",
      "ca1d58067d8142ea8c335a5304bc8207",
      "5f56029d25b04e9bbf9531e36e1b4c82",
      "2079bcd07852415cb51723b997bfc772",
      "159f5a6e52644226a22bdbf5dee5de8e",
      "945d8c6324124ee4aaab6451fab58ba1",
      "730469daafbe4b91be4836e032df8a4e",
      "2cd7dd79dbd646529c8b29dd371e83fe",
      "54ef647589104c108602812cbbea7426",
      "d578a84dfe25422f84c7f18928090383",
      "0e9b534dd0514471bce5db3a1785fc60",
      "ce36e52316674e9889a18575dd2e0be4",
      "11ca0ae929054ee29de9c2ae882a9bc6",
      "c5cf0620686b417bbfc795a6e52c1d5d",
      "9f7c62ea82d54b0ebf38387464f8d15f",
      "d1a0c7cf95944a769178045cfceef8ba",
      "17f2473f5e9f488ba003211e2506b88e",
      "6405a9df6e6245509bb891edc02ef0f1",
      "7499f9c07306439aaa5ce31e216369fa",
      "e481132b1f9442549b410b274690d3bf",
      "d6fe1efe76944b38ae48326ed52f1173",
      "ffdcf60cb9854d5a9fb8bfe36dd77851",
      "533d5fcfce79460bbf1401f249297d8a",
      "cccbb67ed6c1438b8705189d24927185",
      "d11e70cd3f494653bfb03f90ba4f8450",
      "f1b908f840ca4056962f29456c807311",
      "07012ce78e4f4c2e9484cf5057608308",
      "3e453d140c294a5b9e2af2655f8dcd48",
      "5f188660b2ac47c784eb24b78e1bec10",
      "8f0a71332ca64cb49001bedeea5e6441",
      "9c2cab31bfca47238f590681d8a2fb31",
      "055aea4ce309470b931db099116a0072",
      "386eece18d184df18c1f553a84f355e2",
      "d6c5f33e16e9442493b0edb97d8229c0",
      "309cb84b41844c76837cb41ff38528aa",
      "222791eca1c74515b8ffda61e0b82acd",
      "c81419011d2d4c2a80dcd75ff5ef28b3",
      "d3d7bcd99e58466a847a8a77a5b09120",
      "187077f08bd74f908a2652fb22afc25c",
      "c9d53116238545ff8ac55994b79b70d5",
      "3b4875c5cd6c46728682a6f218372554",
      "0661dab121d8449cba68370ccb2b7e8e",
      "28f15c7309824960a123519070119240",
      "80592b3ee5834a789666a5695d6230d7",
      "7cefe3f0b48f49eabfcfaeba0c432a6c",
      "bbcd9da0fddc48e1b873a2b78bd9f803",
      "2e448d169283425289428cc99ddad268",
      "8c5a91ddfafa433abacff74ed9da4b24",
      "87c2f3f1178e4377846bb8ac1077b5b2",
      "6bce874326dd499780d71d653468d5ab",
      "b95e7e06f0be4a64a1a4f1addded35af"
     ]
    },
    "executionInfo": {
     "elapsed": 14148,
     "status": "ok",
     "timestamp": 1743069008862,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "TcORydbTKT6n",
    "outputId": "4a5f5873-5060-4f7e-aa28-acf3476b6af1"
   },
   "outputs": [],
   "source": [
    "# 2. 문장 임베딩 생성\n",
    "embedding_model_name = \"jhgan/ko-sbert-sts\"\n",
    "embedding = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "# 문장 리스트를 입력하여 임베딩 생성\n",
    "pred_embeddings = embedding.encode(test_results)\n",
    "print(pred_embeddings.shape)  # (샘플 개수, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3659,
     "status": "ok",
     "timestamp": 1743069012523,
     "user": {
      "displayName": "김 선우",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "vIcZ__sJKUAA",
    "outputId": "80190ad8-a078-4537-dc85-0ed9d3a62746"
   },
   "outputs": [],
   "source": [
    "# 3. 결과를 CSV 파일로 저장\n",
    "sample_submission_path = submission_path + 'sample_submission.csv'\n",
    "submission = pd.read_csv(sample_submission_path, encoding='utf-8-sig')\n",
    "\n",
    "# 예측 결과 저장\n",
    "submission.iloc[:, 1] = test_results\n",
    "submission.iloc[:, 2:] = pred_embeddings  # 임베딩 벡터 저장\n",
    "\n",
    "# CSV 저장\n",
    "save_submission_path = submission_path + f'{model_name}_submission.csv'\n",
    "submission.to_csv(save_submission_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"최종 결과 저장 완료: {save_submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANcq4DLe9kaQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
