{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVseHXnSuwJx"
   },
   "source": [
    " # ê°œë°œ í™˜ê²½ OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1743064329783,
     "user": {
      "displayName": "ê¹€ì„±í˜¸",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "t_-1LOlfuauY",
    "outputId": "d28f8171-6609-49f2-f79a-b24468008d99"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1743064311707,
     "user": {
      "displayName": "ê¹€ì„±í˜¸",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "j5tqN3NiugIn",
    "outputId": "2f261b0d-0da2-457d-9791-5d2f9e736752"
   },
   "outputs": [],
   "source": [
    "# !head /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 520,
     "status": "ok",
     "timestamp": 1743064312234,
     "user": {
      "displayName": "ê¹€ì„±í˜¸",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "VuIfcnhFugVJ",
    "outputId": "3201cec3-9fed-4406-8901-d7dde0ee64da"
   },
   "outputs": [],
   "source": [
    "# !head -n 3 /proc/meminfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1743064962130,
     "user": {
      "displayName": "ê¹€ì„±í˜¸",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "c2kmpVbKxGeN",
    "outputId": "65060af2-1d37-4676-e9cd-ee2e8e3eee04"
   },
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwsYg3SjA1Ui"
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2218,
     "status": "ok",
     "timestamp": 1743068114842,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "TsGvmOjRNhVn",
    "outputId": "bbd7655d-ac3b-4f55-f860-360ffbdc064d"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8nyvO82AOVR"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain-community langchain-text-splitters langchain langchain-huggingface rank_bm25 transformers torch faiss-cpu pymupdf datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHDfOGR6BaA9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import langchain\n",
    "import langchain_community\n",
    "import langchain_huggingface\n",
    "import transformers\n",
    "import pkg_resources\n",
    "import sentence_transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import  BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1743062445506,
     "user": {
      "displayName": "ê¹€ì„±í˜¸",
      "userId": "00973481409333192946"
     },
     "user_tz": -540
    },
    "id": "J0QPt_7UkwZo",
    "outputId": "0d88b0a0-50f8-4971-8a2e-6e70ffade643"
   },
   "outputs": [],
   "source": [
    "# print(f\"torch version: {torch.__version__}\")\n",
    "# print(f\"pandas version: {pd.__version__}\")\n",
    "# print(f\"tqdm version: {pkg_resources.get_distribution('tqdm').version}\")\n",
    "# print(f\"transformers version: {transformers.__version__}\")\n",
    "# print(f\"sentence_transformers version: {sentence_transformers.__version__}\")\n",
    "# print(f\"langchain version: {langchain.__version__}\")\n",
    "# print(f\"langchain_community version: {langchain_community.__version__}\")\n",
    "# print(f\"langchain_huggingface version: {pkg_resources.get_distribution('langchain_huggingface').version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G14tlIYwAoL6"
   },
   "source": [
    "# ê²½ë¡œ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25662,
     "status": "ok",
     "timestamp": 1743068155009,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "Yn2tkyLBA91H",
    "outputId": "b6273005-414a-4f18-d4b5-c0acfa0ebe74"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9y2aROLlAoSh"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/MyDrive/# á„’á…§á†¸á„ƒá…©á†¼ á„‹á…¥á†¸á„†á…®/á„’á…¡á†«á„‰á…©á†¯á„ƒá…¦á„á…© á„ƒá…¦á„‹á…µá„á…©á†«/A3/' # Colabì—ì„œ ì‹¤í–‰ ì‹œ\n",
    "path = '/' # Local í™˜ê²½ì—ì„œ ì‹¤í–‰ ì‹œ\n",
    "db_path = path + 'DB/'\n",
    "vectorstore_path = path + 'VectorStore/'\n",
    "model_path = path + 'Model/'\n",
    "score_path = path + 'TestScore/'\n",
    "submission_path = path + 'Submission/'\n",
    "\n",
    "# PDF File ê²½ë¡œ\n",
    "pdf_path = path + 'ê±´ì„¤ì•ˆì „ì§€ì¹¨/'\n",
    "file_list = os.listdir(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlRYnJSDAoYU"
   },
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjDue8IwAohB"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(db_path + 'test_preprocessing.csv')\n",
    "\n",
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "test['ê³µì‚¬ì¢…ë¥˜(ëŒ€ë¶„ë¥˜)'] = test['ê³µì‚¬ì¢…ë¥˜'].str.split(' / ').str[0]\n",
    "test['ê³µì‚¬ì¢…ë¥˜(ì¤‘ë¶„ë¥˜)'] = test['ê³µì‚¬ì¢…ë¥˜'].str.split(' / ').str[1]\n",
    "test['ê³µì¢…(ëŒ€ë¶„ë¥˜)'] = test['ê³µì¢…'].str.split(' > ').str[0]\n",
    "test['ê³µì¢…(ì¤‘ë¶„ë¥˜)'] = test['ê³µì¢…'].str.split(' > ').str[1]\n",
    "test['ì‚¬ê³ ê°ì²´(ëŒ€ë¶„ë¥˜)'] = test['ì‚¬ê³ ê°ì²´'].str.split(' > ').str[0]\n",
    "test['ì‚¬ê³ ê°ì²´(ì¤‘ë¶„ë¥˜)'] = test['ì‚¬ê³ ê°ì²´'].str.split(' > ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YTwLOLwAojq"
   },
   "outputs": [],
   "source": [
    "# test data ì „ì²˜ë¦¬\n",
    "data_test = test.apply(\n",
    "    lambda row: {\n",
    "        \"process\": row[\"ì‘ì—…í”„ë¡œì„¸ìŠ¤\"],\n",
    "        \"construct_type\": row[\"ê³µì¢…(ì¤‘ë¶„ë¥˜)\"],\n",
    "        \"object_type\": row[\"ì‚¬ê³ ê°ì²´(ì¤‘ë¶„ë¥˜)\"],\n",
    "        \"reason\": row['ì‚¬ê³ ì›ì¸'], # ì‚¬ê³ ì›ì¸ ì¶”ê°€\n",
    "        \"situation\": (\n",
    "            f\"'{row['ê³µì‚¬ì¢…ë¥˜(ëŒ€ë¶„ë¥˜)']}' ê³µì‚¬ ì¤‘ '{row['ê³µì¢…(ì¤‘ë¶„ë¥˜)']}' ì‘ì—… ì¤‘ '{row['ì‚¬ê³ ì›ì¸']}'ìœ¼ë¡œ ì¸í•´ ì‚¬ê³ ê°€ ë°œìƒí•˜ì˜€ìŠµë‹ˆë‹¤.\"),\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "data_test = pd.DataFrame(list(data_test))\n",
    "\n",
    "# Test ì…ë ¥ ë°ì´í„° ì„¤ì •\n",
    "query = data_test[\"situation\"].tolist() # ì§ˆë¬¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "\n",
    "# # pdf ë½‘ì•„ë‚¼ construct_type_query ì„¤ì •\n",
    "construct_type_query = data_test[\"construct_type\"].tolist()  # \"ê³µì¢…(ì¤‘ë¶„ë¥˜)\"ì„ construct_type_queryë¡œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1743068198731,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "6bkj5L4_L09U",
    "outputId": "5c5da76a-c787-4b09-c5eb-5e56bdfd87de"
   },
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cW6i8zdlAonu"
   },
   "source": [
    "# í•¨ìˆ˜ ì„ ì–¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiYy6GYgG0If"
   },
   "source": [
    "## 1) Chunking í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbobDLgEAotI"
   },
   "outputs": [],
   "source": [
    "# 1. Content Chunking í•¨ìˆ˜ => ì˜ë¯¸ ê¸°ë°˜\n",
    "def chunking():\n",
    "    documents = []\n",
    "    paths = []\n",
    "    total_columns = 0\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ë¶„í• ê¸°\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=overlap)\n",
    "\n",
    "    # Chunking\n",
    "    for idx, file in enumerate(file_list):\n",
    "        # 1. í…ìŠ¤íŠ¸ íŒŒì¼ì„ load -> List[Document] í˜•íƒœë¡œ ë³€í™˜\n",
    "        loader = PyMuPDFLoader(pdf_path + file)\n",
    "\n",
    "        # 2. ë¬¸ì„œ ë¶„í• \n",
    "        chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "        # 3. ê° ì²­í¬ë¥¼ ë²¡í„°í™”í•˜ê³  ì‚½ì…\n",
    "        for chunk in chunks:\n",
    "            documents.append(chunk.page_content)\n",
    "            paths.append(file)\n",
    "\n",
    "        print(\"=\"*50)\n",
    "        print(f\"{idx+1} íŒŒì¼ ëª…: {file}, ë¶„í•  ê°œìˆ˜: {len(chunks)}\")\n",
    "\n",
    "        # 4. ì „ì²´ ì»¬ëŸ¼ ìˆ˜\n",
    "        # ì „ì²´ ì»¬ëŸ¼ ìˆ˜ ì„¸ê¸°\n",
    "        total_columns += len(chunks)\n",
    "        # ì „ì²´ ì»¬ëŸ¼ ìˆ˜ ì¶œë ¥\n",
    "        if idx == len(file_list)-1:\n",
    "            print(f\"DB ì´ Column ìˆ˜ : {total_columns}\")\n",
    "\n",
    "    return documents, paths\n",
    "\n",
    "# 2.sparse ê¸°ë°˜ chunking => í‚¤ì›Œë“œ ê¸°ë°˜\n",
    "def sparse_chunking(file: str):\n",
    "    documents = []\n",
    "    total_columns = 0\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ ë¶„í• ê¸°\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=size, chunk_overlap=overlap)\n",
    "\n",
    "    # Chunking\n",
    "    # 1. í…ìŠ¤íŠ¸ íŒŒì¼ì„ load -> List[Document] í˜•íƒœë¡œ ë³€í™˜\n",
    "    loader = PyMuPDFLoader(pdf_path + file)\n",
    "\n",
    "    # 2. ë¬¸ì„œ ë¶„í• \n",
    "    chunks = loader.load_and_split(text_splitter)\n",
    "\n",
    "    # 3. ê° ì²­í¬ë¥¼ ë²¡í„°í™”í•˜ê³  ì‚½ì…\n",
    "    for chunk in chunks:\n",
    "        documents.append(chunk.page_content)\n",
    "\n",
    "    # 4. ì „ì²´ ì»¬ëŸ¼ ìˆ˜\n",
    "    # ì „ì²´ ì»¬ëŸ¼ ìˆ˜ ì„¸ê¸°\n",
    "    total_columns += len(chunks)\n",
    "\n",
    "    print(f\"DB ì´ Column ìˆ˜ : {total_columns}\")\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ts_PBTF_G4jP"
   },
   "source": [
    "## 2) VectorStore í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg4sHmuNHXRZ"
   },
   "outputs": [],
   "source": [
    "# 3. Title_DenseVectorDB ìƒì„± ë° ì €ì¥\n",
    "def title_vector_store_save(folder_name: str, file_list: list):\n",
    "    # PDF ì œëª© ë¦¬ìŠ¤íŠ¸\n",
    "    pdf_titles = [file.replace('.pdf', '') for file in file_list]\n",
    "\n",
    "    # ì„ë² ë”© ëª¨ë¸\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    print(\"DB ìƒì„± ì¤‘...\")\n",
    "    db = FAISS.from_texts(pdf_titles,\n",
    "                        embedding=embedding_model,\n",
    "                        # docstore=InMemoryDocstore(),\n",
    "                        metadatas=[{\"path\": p} for p in file_list])\n",
    "    print(\"DB ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "    print(\"DB ì €ì¥ ì¤‘...\")\n",
    "    db.save_local(folder_name)\n",
    "    print(\"DB ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "# 4. Content_DenseVectorDB ìƒì„± ë° ì €ì¥\n",
    "def content_vector_store_save(folder_name: str):\n",
    "    # ì„ë² ë”© ëª¨ë¸\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "    documents, paths = chunking()\n",
    "    print(\"DB ìƒì„± ì¤‘...\")\n",
    "    db = FAISS.from_texts(documents,\n",
    "                        embedding=embedding_model,\n",
    "                        # docstore=InMemoryDocstore(),\n",
    "                        metadatas=[{\"path\": p} for p in paths])\n",
    "    print(\"DB ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "    print(\"DB ì €ì¥ ì¤‘...\")\n",
    "    db.save_local(folder_name)\n",
    "    print(\"DB ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "# #VectorDBì— PDF Chunkí™” í•˜ì—¬ ì €ì¥\n",
    "# title_vector_store_save('Title_DB',file_list)\n",
    "# content_vector_store_save('Content_DB')\n",
    "\n",
    "# 5. ì €ì¥ëœ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ\n",
    "def vector_store_load(folder_name: str):\n",
    "    \"\"\"\n",
    "    FAISS ë²¡í„° DB ë¡œë“œ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    faiss_path = vectorstore_path + f\"{folder_name}\"  # ì ˆëŒ€ê²½ë¡œ ì‚¬ìš©\n",
    "\n",
    "    # FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "    if not os.path.exists(f\"{faiss_path}/index.faiss\"):\n",
    "        raise RuntimeError(f\"FAISS ì¸ë±ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {faiss_path}/index.faiss\")\n",
    "\n",
    "    # FAISS ë²¡í„° DB ë¡œë“œ\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-sts\")\n",
    "    vector_store = FAISS.load_local(faiss_path, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "    print(f\"FAISS ë²¡í„° DB ë¡œë“œ ì„±ê³µ: {faiss_path}\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zt7rzg1jHZrz"
   },
   "source": [
    "## 3) Combine Chunked Text í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PCMWr9W2H-1T"
   },
   "outputs": [],
   "source": [
    "# 4. ê²€ìƒ‰í•œ ì²­í¬ë“¤ì„ í•˜ë‚˜ì˜ ì²­í¬ë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜.\n",
    "def format_docs(docs):\n",
    "    \"\"\"\n",
    "    ê²€ìƒ‰í•œ ì²­í¬ë“¤ì„ í•˜ë‚˜ì˜ ì²­í¬ë¡œ í•©ì¹˜ëŠ” í•¨ìˆ˜.\n",
    "\n",
    "    Args:\n",
    "        docs (list): Faissë¡œ ë¶€í„° ê²€ìƒ‰í•œ ë‚´ìš©ì„ ë‹´ì€ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    Returns:\n",
    "        list: í•˜ë‚˜ì˜ ì²­í¬ë¡œ í•©ì¹œ ë¦¬ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    return \"\\n\".join(\n",
    "        [\n",
    "            f\"{doc.page_content}\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ198kEJNLUc"
   },
   "source": [
    "# Model ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11246,
     "status": "ok",
     "timestamp": 1743068214492,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "EaZVQWMoNNjf",
    "outputId": "7191531d-dc50-483e-f238-14ae4498aecf"
   },
   "outputs": [],
   "source": [
    "model_name = 'kobart7'\n",
    "\n",
    "# ì €ì¥ëœ ëª¨ë¸ ê²½ë¡œ\n",
    "load_model_path = model_path + model_name\n",
    "\n",
    "# ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "model = BartForConditionalGeneration.from_pretrained(load_model_path, device_map=\"auto\", num_labels=2)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(load_model_path)\n",
    "print(\"ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "print(\"pad_token:\", tokenizer.pad_token)\n",
    "print(\"pad_token_id:\", tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DflIEzeRAoxd"
   },
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SshMnG_oGIBI"
   },
   "source": [
    "## VectorStore ë¡œë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438,
     "referenced_widgets": [
      "67ba2da202284edfb56f32eaf59e68b1",
      "df5bbe7220e74ee796bfe38c7e3bbd73",
      "ce9ce5ddcfdd4314babd8fb61902eb04",
      "7168cf71aee8435fac06f23563fe01eb",
      "5e9c876d194d4bb79fd6ae15777648ee",
      "03103610d4fc4c01aba0755895f2cf15",
      "bb1a88654ce3438f9d8bfa75ae298e6c",
      "7998e8e7294c491389199e4e49541858",
      "57684e9af1b44526bbceb7c52fb02bed",
      "b241dba6505c41f09c81078f52d10744",
      "32fcfb1f2a1549c7a458ce48d170f74b",
      "78654a8596284788a3547593c37bd6ee",
      "be598f3d84b44ccaaac35608e3486553",
      "86a6dca4632843f2aaf41488c185de28",
      "c83b439da6f042a4b8e8a3c2d2f67a56",
      "b75eb5390e2547cd8422f005112ea46d",
      "974c0a0f3ca3452c9a0d7f1b8130a377",
      "3daa4857d65e4186894a6a5651a65e46",
      "0fcd2257b8094432820881679d855759",
      "4e9c402e85264c2c9aa10064a244ede2",
      "fa6dda283a8f4fa9a1fd60ff44e51110",
      "306f9b9d6d644641a72c587876f6542f",
      "60519d7053844f8c964e97d28d343fe4",
      "fc85c413dfab449984580763b3e2898d",
      "8a0ad1fafb6b41a685cec25b2526fd7d",
      "af096fe6578841ad9fa699202874e7df",
      "552d139d5e8449bb98a983a1554dfb82",
      "16c9f60c63c343bcbc1ba925d1571f80",
      "12ec03d8de3e4039923b607e40bc064c",
      "9af54bc56b674f279c7fc3182c977026",
      "2943abf05a5242a4a49b751b079db856",
      "acf3cbcf6c3445baa82eed65af31daad",
      "12918f20043f4951858de77b8a8acc0a",
      "f50adc3f19464c7cbcb4978bba3fab6f",
      "7e60af2c894947b6b63cfe678966b664",
      "e921dddc17e649b383d45266afff6b4a",
      "346c952b85f84628b98dc3ff17b9c924",
      "e2cdb95561534c4e80a33ecf1b65628f",
      "298a7f1cf4d940b7b87069757644066b",
      "39791206e60e420888dd82f2ce5c6251",
      "bd7dccdf621a4e7ca469c38bc7a5b54b",
      "36dea6726a294a61b25d1f022ac3240f",
      "6b101521218541c681b5c3d1385430e2",
      "41eda6c6e378429cbb242486cc4f5d0e",
      "425a83ec57b24875a0c3d6931ce4ab97",
      "3fcf7d8c711743738a62c2f0a0162433",
      "6a19e938bda347a98f4547014401ed50",
      "33aacdb3b86a42fbb84f22e8e80688fc",
      "3c711ffdea9444e19a965f61b81213d0",
      "2790ba42e97344c89e10b233ba549a19",
      "73c6909efeab4856825a5a0fa6de5997",
      "ed2aa2130d5e4c9db4da685357b13520",
      "64d3e7f1c9954a3bba5340f7e3d8425c",
      "7782002c95b646e6b502b583b0630e6b",
      "36f00d45a79e412f8d02673a50a4f9fb",
      "4797d2e2f39c492cb2fafd5b149ece6a",
      "eaaa84bb82364a1b8f683394b59022dc",
      "1a653e478eb84e0ab6be31bb62cc5e5a",
      "1b6187cfbe2c42f49a0bbd2bf4d8e910",
      "b3ab4ac1f4a5485cb189df9be4681092",
      "dd7a68b65d7144b4ba4641884a67f19c",
      "4f6e02d8e2194ea2ab9112fe30275a97",
      "ee9376252d6c4513bb8eb7e9576b4c3a",
      "abfd98df209444a1bcf7756f6ecda45f",
      "6de7b68c4efe412591edb68f58d00c82",
      "6f5809b0a6ad4f2eadac861b8c05d12f",
      "52b6c71cdaf64547b1d1f54d10caf910",
      "d09522e2e785410daaeb6130c814ae2f",
      "a57a667872b24f8586422749da6c1954",
      "26c42bd219f94b51a98994bdbbf3f56d",
      "876869a660b64fecacbfa0c787b2d56c",
      "bb4c273f72c04e0ab5bc5d0f914ebe42",
      "998f363d5d234ed6a95d837bbd294fbe",
      "72102bb78e4b42628b792a26f8a565f2",
      "8ebd4f78539a47fc8764fb6e23a4967b",
      "4ed11068d6b84434ba9644fee5d2a0d9",
      "876aa84c4acd415ba9dac2fbed458ffa",
      "89eeb2048a4b4696a0a74ef5b60a6cbb",
      "8ec97f29801b4f1c89e9935390d21242",
      "ad5c62d3b65b4f5db6a85d335680cdcb",
      "6e849a932fcc472997e2b4742a6425e1",
      "b63701d1ade94b50837adebb207e96e4",
      "cfa21e9c00cf43c193425162498d353a",
      "b7273e4ae7fa40f0a800930d8f43c3e9",
      "b140c58aaaf2456c8023b6221cbebfa1",
      "b958c72773fd4e12a49590a4b0162434",
      "ae806d9234994d35bb8af8f9f0f7fe0a",
      "7c47cbeb1f0c47ec9d3a4104a29a0e3e",
      "7271a563403f4c46a09c66e644cd4028",
      "994b4b52469a45118766621bd64ac240",
      "005a33422cbc46f085f3a45009364798",
      "b4bc295ff0b74d7cbdddd24e0549b2c0",
      "64f8940042ee4a8183f2f8a648608ba9",
      "71a369fc34bc4420a38ea8bbba686319",
      "11fb91d0c21d439688bac255b3623003",
      "1de880aebb1847ae9951e9cc6abc23cf",
      "b578c83d520441f7a9c5ad528a3d2536",
      "ac5ee2f65398438ab38d7f7a4c3c7e57",
      "dfdcb90dbd3846428ddbd9e3bb911408",
      "dae63b0a8cf646b0a13a437e406d7fdd",
      "116725bacd2348398f3ce1a847f6658b",
      "658a7cf912d34f6c9dd039bf748cf5c4",
      "348039dc7ed04b7fb10c4d7551061d30",
      "4f6e3c7e5a6e4467a3ea06c547ee0de1",
      "b646d398fd954567bced71c415c0b539",
      "a519958f593742ddadb294958e33a635",
      "877fec3044bb41519e6f1160ad78e3dc",
      "0b56b37fc23041f3954b19a79b4d3b49",
      "52716934c1c84d9d86707d705b841458",
      "af0b294b5eda4aa39eb5e7e8a1125048",
      "05cc05596d2f4e2583fa185a79b945c3",
      "56ea2d8ab8d04f1d9f0041b0a3da3b88",
      "ed7c0c27e61848838f15ddc2f27e2218",
      "bee0d8adb58c4a59b9196b9bf793c2f9",
      "5e8352668314474baaf494a8883e7086",
      "ced9f11df2ea493db5943b5c365e00b8",
      "2960acaf8f1c4ec59307d64dfc5b7886",
      "0acc8986339d4af3972a99dc0b4a8f21",
      "109554960a0940538c2fde997ae5f51c",
      "a0877cdcd7b347a090a1dbcf960d3a42",
      "ec5038cc53e748a29f1cb30d572ade74",
      "dabed8b74b1e4352b1e5cad9319dff3d",
      "50d78bf5ed2d4786a62214ad3e220146",
      "fc4c9be253d7460a9cc089ae6579739d",
      "bbb5a341d2bb48c6be9e309c651c1643",
      "631b9c2152564019a1f5d8e9d5bebd35",
      "4e002d984528403087ad9c40023acde9",
      "6adae867f9624fb5a7b5ac31eb506b1f",
      "3e588296dd154a068d9e899a98d07d58",
      "b5fae32f7de74c79a5a7216503ab0a8f",
      "578d5dd57c8e4294abc38c95cf2d9884",
      "b16c1accf5594d9bbd77f25a1045a3d4"
     ]
    },
    "executionInfo": {
     "elapsed": 28918,
     "status": "ok",
     "timestamp": 1743068243410,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "VJ8GwEULGNFQ",
    "outputId": "1ad27eac-00b5-4be8-ed8c-822d36457e2d"
   },
   "outputs": [],
   "source": [
    "# chunk size ì¡°ì •\n",
    "size = 300\n",
    "overlap = 50\n",
    "\n",
    "# Hybrid Retriever í•¨ìˆ˜ë¡œ êµ¬ì„± (3ê°œì˜ pdf)\n",
    "title_db = vector_store_load(\"Title_DB\")\n",
    "content_db = vector_store_load(f\"Content_DB_{size}_{overlap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUew-IM_Ao2x"
   },
   "outputs": [],
   "source": [
    "# re-rank retriever í•¨ìˆ˜ë¡œ êµ¬ì„± (3ê°œì˜ pdf)\n",
    "def rerank_retriever(construct_type_query: str, query: str, k: int = 2):\n",
    "    \"\"\"\n",
    "    Fine-Tuned LLaMA + Hybrid Retriever ê¸°ë°˜ RAG ì‹¤í–‰ í•¨ìˆ˜\n",
    "    construct_type_query: PDF ê²€ìƒ‰ì— ì‚¬ìš©í•  'ê³µì¢…(ì¤‘ë¶„ë¥˜)' ì •ë³´\n",
    "    query: ì‹¤ì œ ê²€ìƒ‰ì— ì‚¬ìš©í•  'ì‚¬ê³ ìƒí™©'\n",
    "    k: ê²€ìƒ‰í•  PDF ê°œìˆ˜\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Hybrid Retriever ì‹œì‘ â†’ construct_type_query: {construct_type_query}, query: {query}\")\n",
    "\n",
    "    # 1. ì €ì¥ëœ FAISS ë²¡í„° DB ë¡œë“œ\n",
    "    # embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "    title_db = vector_store_load(\"Title_DB\")\n",
    "\n",
    "    # 2. FAISS ë²¡í„° ê²ìƒ‰ ìˆ˜í–‰ -> 'ê³µì¢…(ì¤‘ë¶„ë¥˜)'ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ PDF ì°¾ê¸°\n",
    "    result = title_db.similarity_search(construct_type_query, k=3)  # ê°€ì¥ ìœ ì‚¬í•œ 3ê°œ ì°¾ê¸°\n",
    "\n",
    "    # ê²€ìƒ‰ëœ PDF íŒŒì¼ ëª©ë¡\n",
    "    pdfs = [doc.metadata[\"path\"] for doc in result]\n",
    "    print(f\" ì„ íƒëœ PDF: {pdfs}\")\n",
    "\n",
    "    # 3. Content DB ë¡œë“œ (ì„ íƒëœ PDFì—ì„œ ê²€ìƒ‰)\n",
    "    content_db = vector_store_load(f\"Content_DB_{size}_{overlap}\")\n",
    "\n",
    "    # FAISS ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± (Dense Retriever)\n",
    "    dense_retriever = content_db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"filter\": {\"path\": {\"$in\": pdfs}}, \"k\": k}  # ì„ íƒëœ PDFì—ì„œ ê²€ìƒ‰\n",
    "    )\n",
    "\n",
    "    # 4. BM25ë¥¼ ìœ„í•œ Sparse ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    all_documents = []\n",
    "    for pdf in pdfs:\n",
    "        # BM25 ê²€ìƒ‰ìš© ë¬¸ì„œ ê°ì²´ ìƒì„±\n",
    "        documents = [Document(page_content=doc) for doc in sparse_chunking(pdf)]\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "    sparse_retriever = BM25Retriever.from_documents(all_documents)\n",
    "\n",
    "    # 5. Hybrid Retriever ìƒì„± (FAISS + BM25 ê²°í•©)\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[sparse_retriever, dense_retriever],\n",
    "        weights=[0.7, 0.3]  # ê°€ì¤‘ì¹˜ ì„¤ì •\n",
    "    )\n",
    "\n",
    "    # Re-Rank ëª¨ë¸ ì„¤ì •\n",
    "    reranker_model_name = \"BAAI/bge-reranker-v2-m3\"  # Hugging Face Re-Ranker ëª¨ë¸\n",
    "\n",
    "    rerank_model = HuggingFaceCrossEncoder(model_name=reranker_model_name)\n",
    "    compressor = CrossEncoderReranker(model=rerank_model, top_n=k) # ê°€ì ¸ì˜¤ê³ ì í•˜ëŠ” ì²­í¬ì˜ ê°¯ìˆ˜ë¥¼ top_nì— ê¸°ì…\n",
    "\n",
    "    # re-ranker ì ìš©\n",
    "    compression_retriever = ContextualCompressionRetriever(\n",
    "        base_compressor=compressor,\n",
    "        base_retriever=ensemble_retriever\n",
    "    )\n",
    "\n",
    "    return compression_retriever\n",
    "\n",
    "def hybrid_retriever(construct_type_query: str, query: str, k: int = 2):\n",
    "    \"\"\"\n",
    "    Fine-Tuned LLaMA + Hybrid Retriever ê¸°ë°˜ RAG ì‹¤í–‰ í•¨ìˆ˜\n",
    "    construct_type_query: PDF ê²€ìƒ‰ì— ì‚¬ìš©í•  'ê³µì¢…(ì¤‘ë¶„ë¥˜)' ì •ë³´\n",
    "    query: ì‹¤ì œ ê²€ìƒ‰ì— ì‚¬ìš©í•  'ì‚¬ê³ ìƒí™©'\n",
    "    k: ê²€ìƒ‰í•  PDF ê°œìˆ˜\n",
    "    \"\"\"\n",
    "    # 1. FAISS ë²¡í„° ê²ìƒ‰ ìˆ˜í–‰ -> 'ê³µì¢…(ì¤‘ë¶„ë¥˜)'ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ PDF ì°¾ê¸°\n",
    "    result = title_db.similarity_search(construct_type_query, k=3)  # ê°€ì¥ ìœ ì‚¬í•œ 3ê°œ ì°¾ê¸°\n",
    "\n",
    "    # ê²€ìƒ‰ëœ PDF íŒŒì¼ ëª©ë¡\n",
    "    pdfs = [doc.metadata[\"path\"] for doc in result]\n",
    "\n",
    "    # 2. Content DB ë¡œë“œ (ì„ íƒëœ PDFì—ì„œ ê²€ìƒ‰)\n",
    "\n",
    "    # FAISS ë¦¬íŠ¸ë¦¬ë²„ ìƒì„± (Dense Retriever)\n",
    "    dense_retriever = content_db.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"filter\": {\"path\": {\"$in\": pdfs}}, \"k\": k}  # ì„ íƒëœ PDFì—ì„œ ê²€ìƒ‰\n",
    "    )\n",
    "\n",
    "    # 3. BM25ë¥¼ ìœ„í•œ Sparse ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    all_documents = []\n",
    "    for pdf in pdfs:\n",
    "        # BM25 ê²€ìƒ‰ìš© ë¬¸ì„œ ê°ì²´ ìƒì„±\n",
    "        documents = [Document(page_content=doc) for doc in sparse_chunking(pdf)]\n",
    "        all_documents.extend(documents)\n",
    "\n",
    "    sparse_retriever = BM25Retriever.from_documents(all_documents)\n",
    "\n",
    "    # 4. Hybrid Retriever ìƒì„± (FAISS + BM25 ê²°í•©)\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[sparse_retriever, dense_retriever],\n",
    "        weights=[0.2, 0.8]  # ê°€ì¤‘ì¹˜ ì„¤ì •\n",
    "    )\n",
    "\n",
    "    return ensemble_retriever\n",
    "\n",
    "# ensemble retrieverì—ì„œ queryê´€ë ¨ ì²­í¬ë“¤ ë½‘ì•„ì˜¤ê¸°\n",
    "def retrieved_chunk(construct_type_query: str, query: str, k: int = 3):\n",
    "    \"\"\"\n",
    "    Hybrid Retrieverë¥¼ ì‚¬ìš©í•˜ì—¬ queryì— ëŒ€í•œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰\n",
    "    \"\"\"\n",
    "    ensemble_retriever = hybrid_retriever(construct_type_query, query, k)\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ê´€ë ¨ ì²­í¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n",
    "    retrieved_chunks = ensemble_retriever.invoke(query)\n",
    "\n",
    "    # ê²€ìƒ‰ëœ ì²­í¬ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "    retrieved_text = format_docs(retrieved_chunks)\n",
    "\n",
    "    return retrieved_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cAsZ2Y8KItg"
   },
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RoEojb7hAo-M"
   },
   "outputs": [],
   "source": [
    "# LangChain Prompt Template ìƒì„±(íŒŒì¸íŠœë‹í•œ í…œí”Œë¦¿ ìœ ì§€ + ê²€ìƒ‰ëœ ì²­í¬ í™œìš©)\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"process\",\"construct_type\", \"object_type\", \"context\", \"situation\"],\n",
    "    template=(\n",
    "'''\n",
    "ì œê³µëœ dataëŠ” ê±´ì„¤ ê³µì‚¬í˜„ì¥ì—ì„œ ë°œìƒí•œ ì‚¬ê³  ìƒí™©ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ situationì„ ë¶„ì„í•˜ê³  contextë¥¼ ì°¸ê³ í•´ ì¬ë°œë°©ì§€ ëŒ€ì±…ì„ í¬í•¨í•œ ëŒ€ì‘ì±…ì„ responseì— ì‘ì„±í•˜ì„¸ìš”.\n",
    "### context:\n",
    "{context}\n",
    "\n",
    "### process:\n",
    "{process}\n",
    "\n",
    "### construct_type:\n",
    "{construct_type}\n",
    "\n",
    "### object_type:\n",
    "{object_type}\n",
    "\n",
    "### situation:\n",
    "{situation}\n",
    "\n",
    "â€» Example response:\n",
    "- ì‘ì—…ì ì•ˆì „êµìœ¡ ë° ì¬ë°œ ë°©ì§€ ëŒ€ì±… ìˆ˜ë¦½ê³¼ ì‘ì—… ì „ ì•ˆì „êµìœ¡ ì² ì € ë° ê´€ë¦¬ì ì¶”ê°€ ë°°ì¹˜ë¥¼ í†µí•œ ë™ì¢… ì‚¬ê³  ì˜ˆë°©.\n",
    "- ê·¼ë¡œì ë³´í–‰ í†µë¡œ êµ¬ê°„ ì•ˆì „í‘œì§€íŒ ì„¤ì¹˜ì™€ íŠ¹ë³„ì•ˆì „êµìœ¡ ì‹¤ì‹œ, ì¼ì¼ ì‘ì—… íˆ¬ì… ì „ ìƒì‹œ êµìœ¡, ê´€ë¦¬ ëŒ€ìƒ ì„ ì • ë“±ì„ í†µí•œ ì´ë™ êµ¬ê°„ ë³´í–‰ ì•ˆì „ í™•ë³´ì™€ ì‘ì—…ì ì•ˆì „ êµìœ¡ ì§€ì‹œ.\n",
    "\n",
    "### response:\n",
    "''')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wd60O18TApD2"
   },
   "source": [
    "# ì¶”ë¡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRT9uBf6KTka"
   },
   "outputs": [],
   "source": [
    "# generate_text í•¨ìˆ˜\n",
    "def generate_answer(ts, prompt, model, tokenizer, max_new_tokens=65):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ì´ ì¬ë°œ ë°©ì§€ ëŒ€ì±… ë° í–¥í›„ ì¡°ì¹˜ ê³„íšì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    )\n",
    "\n",
    "\n",
    "    process = ts['process']\n",
    "    construct_type = ts['construct_type']\n",
    "    object_type = ts['object_type']\n",
    "    situation = ts['situation']\n",
    "    reason = ts['reason']\n",
    "\n",
    "\n",
    "    # ì…ë ¥ ë¬¸ì¥ í† í°í™” ë° GPUë¡œ ì´ë™\n",
    "    input_ids = tokens.input_ids.to(device)\n",
    "    # print('prompt:',tokenizer.decode(input_ids[0], skip_special_tokens=True))\n",
    "    attention_mask = tokens.attention_mask.to(device)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        temperature=0.7,\n",
    "        top_k=40,\n",
    "        top_p=0.85,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        eos_token_id=tokenizer.eos_token_id  # <-- ì´ ë¶€ë¶„ì´ í•µì‹¬\n",
    "    )\n",
    "\n",
    "\n",
    "    # ìƒì„±ëœ í† í°ì„ ë‹¤ì‹œ ë¬¸ì¥ìœ¼ë¡œ ë³€í™˜\n",
    "    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # âœ… í›„ì²˜ë¦¬: ë§ˆì§€ë§‰ ë§ˆì¹¨í‘œ(.)ê¹Œì§€ë§Œ ìë¥´ê¸°\n",
    "    if '.' in generated_text:\n",
    "        last_period_index = generated_text.rfind('.')  # ë§ˆì§€ë§‰ ë§ˆì¹¨í‘œ ìœ„ì¹˜\n",
    "        generated_text = generated_text[:last_period_index + 1].strip()\n",
    "    else:\n",
    "        generated_text = generated_text.strip()\n",
    "\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "\n",
    "# RAG ì‹¤í–‰ (Hybrid Retriever + kobart)\n",
    "def rag_pipeline(ts, model, tokenizer, k=2):\n",
    "    \"\"\"\n",
    "    RAG ì‹œìŠ¤í…œ ì‹¤í–‰: Hybrid Retriever â†’ Fine-tuned kobart ê¸°ë°˜ ìƒì„±\n",
    "    \"\"\"\n",
    "    # print(\"ğŸ” RAG ì‹¤í–‰ ì‹œì‘...\")\n",
    "\n",
    "    # Hybrid Retriever ì‹¤í–‰í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰\n",
    "    retrieved_text = retrieved_chunk(ts['construct_type'], ts['situation'], k) # 'situation'(ì‚¬ê³ ìƒí™©)ì—ì„œ 'reason'(ì‚¬ê³ ì›ì¸)ìœ¼ë¡œ ë³€ê²½\n",
    "\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n",
    "    formatted_prompt = prompt_template.format(process=ts['process'],\n",
    "                                              construct_type=ts['construct_type'],\n",
    "                                              object_type=ts['object_type'],\n",
    "                                              context=retrieved_text,\n",
    "                                              situation=ts['situation'])\n",
    "\n",
    "    # ë¬¸ì¥ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ\n",
    "    generated_response = generate_answer(ts, formatted_prompt, model, tokenizer)\n",
    "\n",
    "    return generated_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZ9GjqFvQOJf"
   },
   "source": [
    "## ì¶”ë¡  ì‹¤í—˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12760,
     "status": "ok",
     "timestamp": 1743068256266,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "vF6sFsBNKTwZ",
    "outputId": "20b637e2-c26d-4464-cf8a-98bf972028e9"
   },
   "outputs": [],
   "source": [
    "# ëœë¤í•˜ê²Œ 10ê°œì˜ ì¸ë±ìŠ¤ ì„ íƒ\n",
    "random_indices = random.sample(range(len(data_test)), 10)\n",
    "\n",
    "for i in random_indices:\n",
    "    ts = data_test.iloc[i]\n",
    "    process = ts['process']\n",
    "    construct_type = ts['construct_type']\n",
    "    object_type = ts['object_type']\n",
    "    situation = ts['situation']\n",
    "    generated_text = rag_pipeline(ts, model, tokenizer)\n",
    "    print(f\"ì‚¬ê³  ìƒí™©: {situation}\")\n",
    "    print(f\"ìƒì„±ëœ ë¬¸ì¥: {generated_text}\")\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA1wM2kbKTqT"
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 738417,
     "status": "ok",
     "timestamp": 1743068994699,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "xaRr0j7MKT1L",
    "outputId": "0bdec32f-1e9f-4a5d-99af-c6ad4c796d99"
   },
   "outputs": [],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥\n",
    "test_results = []\n",
    "\n",
    "print(\"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œì‘... ì´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜:\", len(data_test))\n",
    "\n",
    "for idx, row in tqdm(data_test.iterrows(), total=len(data_test), desc=\"Processing\"):\n",
    "    # RAG ì²´ì¸ í˜¸ì¶œ ë° ê²°ê³¼ ìƒì„±\n",
    "    generated_text = rag_pipeline(row, model, tokenizer)  # ê°œë³„ í–‰(row) ì „ë‹¬\n",
    "    test_results.append(generated_text)\n",
    "\n",
    "print(\"\\ní…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì™„ë£Œ! ì´ ê²°ê³¼ ìˆ˜:\", len(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419,
     "referenced_widgets": [
      "9e4f2dd21bd449b9a36093b7ac2a9035",
      "955d93ec0a644d9ab50515e2af3f96cd",
      "0e8f782743ee446e8982f11c6d798bcf",
      "580e7e6616f944ca9cca0d89cee2ebba",
      "14c2f5512f3542489be10a52367d53b2",
      "da9903a2594741cbbc9a712db55963a2",
      "90d5b2b773f04482ad32eb6f82630d4b",
      "08145901414a4572bc8faecd9829f8ae",
      "47dac9a1149f4ea2846af02f093a4531",
      "991149a173224d6f8bc474457c9ce699",
      "3ca477a1669c4140b04bd435c4b498fa",
      "2264ffd9125949ed8184439eece1380e",
      "cdcaa0e3d6b44a1d99661f07d0fd00f2",
      "3828d548c5074b968379b3be41d2f572",
      "d2b7f4a51d6c4fcfb12f92f80dee802a",
      "4a7371664a754805811d1a29559babef",
      "f9c9f41c880649dab7f6d82b6ad97bae",
      "36d4768f8ea947c4a6b933e9ec5b2088",
      "c644056c83f64afb8e327a199dd926bb",
      "b2249646dcd94d1a8a873d8115dd6a26",
      "b3d9e8f3970f4d858f7033688f8e4316",
      "550d6e06aee14c2fb637fb541ef6273d",
      "f3c46a143c63425f8dc14c2f39984c80",
      "84f1f4afbe474a28a11c7f07c2cb232d",
      "14ef9f85a5e844c9aa886919f7523c1a",
      "c9683511c9354d5a9c27a2b0183cbdaa",
      "5ab74c963d904b53af6ce3b95f278c33",
      "d7d9de1817354fcb8fbdb869be2e51a6",
      "73c95c48997c46059e08395cbf90b4ed",
      "24559150b3644ee3816891803cbe516b",
      "017d8a12d89b45fda73d611bcefd0667",
      "a46a484eb36b4616ae49e4037e1ab59b",
      "c1b052c141c34cae852ea74bf3f9a1b6",
      "4ddbd7e71a9a4b47af0335f8e987e226",
      "24d4d538f81b49e0ba5b5b1fd90e6a8c",
      "6a8425538972480cae9309312a0606c3",
      "b0391cd18ee047e79a011ebb805b1bcf",
      "6d2a8d73fca04d13a3a0eb72c5d7966c",
      "bd5918cf208c4fedb306976a2cb76919",
      "70c6b75814774f9c9335d4abf6f0eec0",
      "98afebbc254e4e3b8dd74fa886152582",
      "800970621adf4d889e7dea5d2cfc43b7",
      "121608618e1647e8bede99377f273f79",
      "d786b9846de74104b025b9ac46320834",
      "3d54e701905846fb890e51f94f89aa12",
      "56f048fb92564f92add5d9294a008a77",
      "3a7dbc6d43734391a302bacb36331e0b",
      "aa4bf612a6434201af2db582f0ff2036",
      "d15c4ad94556414cb392334795ef5a75",
      "6ac146bff1be4ed4b89c9169344a5bb3",
      "d8d8bc76a7954fe2b14a28d746987ff8",
      "6eea708e0ba8471998591a1af77299fa",
      "de7a58266deb4aaa86454526f63fc9b5",
      "a80ae20debb4471991f984a83b48d0a3",
      "71b47f5959114f4192a095b9b11b8a97",
      "5fa3a683cf5f4d74895974635beb4a08",
      "a9338321ca1b46b49dd05a449b9be297",
      "a39cfddbfc984466a88cdd9f8e9cbcfe",
      "0e8919e9887f45ae8ca2e7ae34620f9a",
      "9af55322bb30480caf15218c51e1af72",
      "9f3763dbdd854ef08372819198faf605",
      "d92d656cb81e480cb7c29658e2bb4303",
      "41d6801594c040e99a778a64d6be3599",
      "d67813fe137b4872a505f26433645705",
      "b26d505395c54a779c2e3880f125ecb5",
      "321e717556a54aeb841eeaf904ba0394",
      "760a168618b6403c8a52a8403a813fb8",
      "54597ec970ff434c89546a10feb7dca2",
      "7e857c4ea4d34e21acb3f1e86be0234b",
      "644c3313f64f4600b6d25a95b6096252",
      "94b4cd7fe1724c53ac146b277add0263",
      "b7cde26aea7e407da14074be5120c36d",
      "df94987aba3548afaf832e46bc7f03cc",
      "650e3c68562b4045ba98d847bf8e92d6",
      "83236de0042b4816806dfe505e86ef8d",
      "fca622cf453e4a269196bcfc96cce7a6",
      "c45cb9b142d74bf78313de67d6210116",
      "56dc585569d94c089d47521fa80a39d3",
      "2498ffee40074b3a8e4fada352725425",
      "28fd0f521edc437fac11a3199b240586",
      "8df8dbb9cb244b48b577ed6c78620d5b",
      "f6d2d392dbfb465691a7d64c3e2a05d3",
      "ca1d58067d8142ea8c335a5304bc8207",
      "5f56029d25b04e9bbf9531e36e1b4c82",
      "2079bcd07852415cb51723b997bfc772",
      "159f5a6e52644226a22bdbf5dee5de8e",
      "945d8c6324124ee4aaab6451fab58ba1",
      "730469daafbe4b91be4836e032df8a4e",
      "2cd7dd79dbd646529c8b29dd371e83fe",
      "54ef647589104c108602812cbbea7426",
      "d578a84dfe25422f84c7f18928090383",
      "0e9b534dd0514471bce5db3a1785fc60",
      "ce36e52316674e9889a18575dd2e0be4",
      "11ca0ae929054ee29de9c2ae882a9bc6",
      "c5cf0620686b417bbfc795a6e52c1d5d",
      "9f7c62ea82d54b0ebf38387464f8d15f",
      "d1a0c7cf95944a769178045cfceef8ba",
      "17f2473f5e9f488ba003211e2506b88e",
      "6405a9df6e6245509bb891edc02ef0f1",
      "7499f9c07306439aaa5ce31e216369fa",
      "e481132b1f9442549b410b274690d3bf",
      "d6fe1efe76944b38ae48326ed52f1173",
      "ffdcf60cb9854d5a9fb8bfe36dd77851",
      "533d5fcfce79460bbf1401f249297d8a",
      "cccbb67ed6c1438b8705189d24927185",
      "d11e70cd3f494653bfb03f90ba4f8450",
      "f1b908f840ca4056962f29456c807311",
      "07012ce78e4f4c2e9484cf5057608308",
      "3e453d140c294a5b9e2af2655f8dcd48",
      "5f188660b2ac47c784eb24b78e1bec10",
      "8f0a71332ca64cb49001bedeea5e6441",
      "9c2cab31bfca47238f590681d8a2fb31",
      "055aea4ce309470b931db099116a0072",
      "386eece18d184df18c1f553a84f355e2",
      "d6c5f33e16e9442493b0edb97d8229c0",
      "309cb84b41844c76837cb41ff38528aa",
      "222791eca1c74515b8ffda61e0b82acd",
      "c81419011d2d4c2a80dcd75ff5ef28b3",
      "d3d7bcd99e58466a847a8a77a5b09120",
      "187077f08bd74f908a2652fb22afc25c",
      "c9d53116238545ff8ac55994b79b70d5",
      "3b4875c5cd6c46728682a6f218372554",
      "0661dab121d8449cba68370ccb2b7e8e",
      "28f15c7309824960a123519070119240",
      "80592b3ee5834a789666a5695d6230d7",
      "7cefe3f0b48f49eabfcfaeba0c432a6c",
      "bbcd9da0fddc48e1b873a2b78bd9f803",
      "2e448d169283425289428cc99ddad268",
      "8c5a91ddfafa433abacff74ed9da4b24",
      "87c2f3f1178e4377846bb8ac1077b5b2",
      "6bce874326dd499780d71d653468d5ab",
      "b95e7e06f0be4a64a1a4f1addded35af"
     ]
    },
    "executionInfo": {
     "elapsed": 14148,
     "status": "ok",
     "timestamp": 1743069008862,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "TcORydbTKT6n",
    "outputId": "4a5f5873-5060-4f7e-aa28-acf3476b6af1"
   },
   "outputs": [],
   "source": [
    "# 2. ë¬¸ì¥ ì„ë² ë”© ìƒì„±\n",
    "embedding_model_name = \"jhgan/ko-sbert-sts\"\n",
    "embedding = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "# ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì—¬ ì„ë² ë”© ìƒì„±\n",
    "pred_embeddings = embedding.encode(test_results)\n",
    "print(pred_embeddings.shape)  # (ìƒ˜í”Œ ê°œìˆ˜, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3659,
     "status": "ok",
     "timestamp": 1743069012523,
     "user": {
      "displayName": "ê¹€ ì„ ìš°",
      "userId": "08412778136116235349"
     },
     "user_tz": -540
    },
    "id": "vIcZ__sJKUAA",
    "outputId": "80190ad8-a078-4537-dc85-0ed9d3a62746"
   },
   "outputs": [],
   "source": [
    "# 3. ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "sample_submission_path = submission_path + 'sample_submission.csv'\n",
    "submission = pd.read_csv(sample_submission_path, encoding='utf-8-sig')\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n",
    "submission.iloc[:, 1] = test_results\n",
    "submission.iloc[:, 2:] = pred_embeddings  # ì„ë² ë”© ë²¡í„° ì €ì¥\n",
    "\n",
    "# CSV ì €ì¥\n",
    "save_submission_path = submission_path + f'{model_name}_submission.csv'\n",
    "submission.to_csv(save_submission_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_submission_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANcq4DLe9kaQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
